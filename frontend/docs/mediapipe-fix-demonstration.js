/**
 * MediaPipe Fixed Implementation Demonstration
 * Shows the correct usage pattern for the fixed MediaPipe Manager
 */

// Example 1: Basic initialization and face detection
async function demonstrateBasicUsage() {
    console.log('üöÄ MediaPipe Fixed Implementation Demonstration');
    
    try {
        // Import the fixed MediaPipe Manager
        const { default: MediaPipeManager } = await import('../src/utils/MediaPipeManager.js');
        
        // Create instance
        const mediaManager = new MediaPipeManager();
        console.log('‚úÖ MediaPipe Manager instance created');
        
        // Initialize using the correct FilesetResolver pattern
        console.log('üîÑ Initializing MediaPipe with FilesetResolver...');
        const success = await mediaManager.initialize();
        
        if (success) {
            console.log('‚úÖ MediaPipe initialized successfully!');
            
            // Get status information
            const status = mediaManager.getStatus();
            console.log('üìä MediaPipe Status:', status);
            
            // Test with a sample image (you would provide a real image)
            const results = await mediaManager.analyzeFace('path/to/image.jpg');
            console.log('üë§ Face analysis results:', results);
            
            // Clean up when done
            mediaManager.dispose();
            console.log('üßπ MediaPipe disposed');
            
        } else {
            console.error('‚ùå MediaPipe initialization failed');
        }
        
    } catch (error) {
        console.error('‚ùå Error:', error);
    }
}

// Example 2: Advanced usage with error handling and performance monitoring
async function demonstrateAdvancedUsage() {
    console.log('üî¨ Advanced MediaPipe Usage Demonstration');
    
    const mediaManager = new (await import('../src/utils/MediaPipeManager.js')).default();
    
    try {
        // Initialize with performance monitoring
        const startTime = performance.now();
        await mediaManager.initialize();
        const initTime = performance.now() - startTime;
        
        console.log(`‚ö° Initialization completed in ${initTime.toFixed(2)}ms`);
        
        // Get detailed diagnostics
        const diagnostics = mediaManager.getConnectionDiagnostics();
        console.log('üîç Connection diagnostics:', diagnostics);
        
        // Simulate face analysis with multiple images
        const testImages = ['image1.jpg', 'image2.jpg', 'image3.jpg'];
        
        for (const imagePath of testImages) {
            try {
                const analysisStart = performance.now();
                const results = await mediaManager.analyzeFace(imagePath, { includeDebug: true });
                const analysisTime = performance.now() - analysisStart;
                
                console.log(`üìä Analysis of ${imagePath}:`);
                console.log(`  - Face detected: ${results.hasFace}`);
                console.log(`  - Landmarks: ${results.debug?.landmarkCount || 0}`);
                console.log(`  - Time: ${analysisTime.toFixed(2)}ms`);
                console.log(`  - Confidence: ${(results.confidence * 100).toFixed(1)}%`);
                
            } catch (analysisError) {
                console.warn(`‚ö†Ô∏è Analysis failed for ${imagePath}:`, analysisError.message);
            }
        }
        
        // Get final performance metrics
        const finalStatus = mediaManager.getStatus();
        console.log('üìà Final performance metrics:', finalStatus.performanceMetrics);
        
    } catch (error) {
        console.error('‚ùå Advanced usage error:', error);
        
        // Attempt recovery
        if (mediaManager.retryCount < mediaManager.maxRetries) {
            console.log('üîÑ Attempting recovery...');
            try {
                await mediaManager.reinitialize();
                console.log('‚úÖ Recovery successful');
            } catch (recoveryError) {
                console.error('‚ùå Recovery failed:', recoveryError);
            }
        }
        
    } finally {
        mediaManager.dispose();
    }
}

// Example 3: Integration with existing viseme analysis system
async function demonstrateVisemeIntegration() {
    console.log('üëÑ MediaPipe Viseme Integration Demonstration');
    
    const mediaManager = new (await import('../src/utils/MediaPipeManager.js')).default();
    
    try {
        await mediaManager.initialize();
        
        // Simulate video frame processing for lip sync
        const processVideoFrame = async (videoElement) => {
            try {
                // Analyze current frame
                const results = await mediaManager.analyzeFace(videoElement);
                
                if (results.hasFace && results.faceBlendshapes.length > 0) {
                    const blendshapes = results.faceBlendshapes[0].categories;
                    
                    // Extract viseme-relevant blendshapes
                    const visemeData = {
                        mouthOpen: blendshapes.find(b => b.categoryName === 'jawOpen')?.score || 0,
                        mouthWide: blendshapes.find(b => b.categoryName === 'mouthStretchLeft')?.score || 0,
                        lipsPucker: blendshapes.find(b => b.categoryName === 'mouthPucker')?.score || 0,
                        timestamp: results.timestamp
                    };
                    
                    console.log('üëÑ Viseme data:', visemeData);
                    return visemeData;
                }
                
            } catch (error) {
                console.warn('‚ö†Ô∏è Frame processing error:', error.message);
                return null;
            }
        };
        
        // Example: Process a single frame (in real usage, you'd call this repeatedly)
        // const videoElement = document.getElementById('myVideo');
        // const visemeData = await processVideoFrame(videoElement);
        
        console.log('üëÑ Viseme integration ready');
        
    } catch (error) {
        console.error('‚ùå Viseme integration error:', error);
    } finally {
        mediaManager.dispose();
    }
}

// Export demonstration functions
export {
    demonstrateBasicUsage,
    demonstrateAdvancedUsage,
    demonstrateVisemeIntegration
};

// Auto-run basic demonstration if loaded directly
if (typeof window !== 'undefined') {
    window.mediaPipeDemo = {
        basic: demonstrateBasicUsage,
        advanced: demonstrateAdvancedUsage,
        viseme: demonstrateVisemeIntegration
    };
    
    console.log('üìã MediaPipe demonstrations available:');
    console.log('  - window.mediaPipeDemo.basic()');
    console.log('  - window.mediaPipeDemo.advanced()');
    console.log('  - window.mediaPipeDemo.viseme()');
}